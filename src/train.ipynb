{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ec2b36-0149-43b7-b4ba-7871b8d45d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.gptmodel import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d23feb8-a522-4258-90a7-0c74ad37f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf0a0e-0358-4ec9-9302-4bd57b06de88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ed6a11-1e99-444f-b4b2-7e54873f2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85caa2a-c32c-4da7-a7f4-aa3d92c04fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59742e54-fcc7-49a2-b971-66d24cfcd605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "177bc581-d01c-4691-9e05-2b30b2738808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitGPTModel(L.LightningModule):\n",
    "    def __init__(self, GPTModel):\n",
    "        super().__init__()\n",
    "        self.model = GPTModel\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        return self.loss(logits, y)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        logits = self.model(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def loss(self, output, expected):\n",
    "        loss = nn.functional.cross_entropy(\n",
    "            output.flatten(0, 1), expected.flatten()\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(), lr=1e-4, weight_decay=0.1\n",
    "        )\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ad0b8-2672-4afb-891b-cee4e1dfe3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57750fa6-f436-42f1-87fa-2b7c52f01543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.data import create_dataloader_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "968ce8c6-9d09-47d7-a447-e680bfdb273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../data/TinyStories/TinyStoriesV2-GPT4-train.txt\"\n",
    "with open(train_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_text = f.read()\n",
    "\n",
    "train_len = len(train_text)\n",
    "train_text = train_text[:train_len // 1000]\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_text,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5601360e-c8f4-4753-9e7c-f62e7c099c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file = \"../data/TinyStories/TinyStoriesV2-GPT4-valid.txt\"\n",
    "with open(val_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    val_text = f.read()\n",
    "\n",
    "val_len = len(val_text)\n",
    "val_text = val_text[:val_len // 1000]\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_text,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049ff93-2430-41cd-a7b5-0ac4439f5a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e34309-62e4-4439-a093-bc421b7fabc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995d95d-edd2-4a21-9e69-0361d5bf21b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de47265-4440-4c7b-a47d-ad8b3257b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "litmodel = LitGPTModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af01d54-1a9d-484d-bd23-573bb249cb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/gebrial/miniforge3/envs/fromscratch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | model | GPTModel | 162 M  | train\n",
      "-------------------------------------------\n",
      "162 M     Trainable params\n",
      "0         Non-trainable params\n",
      "162 M     Total params\n",
      "649.679   Total estimated model params size (MB)\n",
      "187       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████| 1072/1072 [03:09<00:00,  5.64it/s, v_num=5]\n",
      "Validation: |                                                                                     | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█████▎                                                     | 1/11 [00:00<00:00, 27.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██████████▋                                                | 2/11 [00:00<00:00, 30.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████████████████                                           | 3/11 [00:00<00:00, 30.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|█████████████████████▍                                     | 4/11 [00:00<00:00, 30.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|██████████████████████████▊                                | 5/11 [00:00<00:00, 33.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|████████████████████████████████▏                          | 6/11 [00:00<00:00, 33.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|█████████████████████████████████████▌                     | 7/11 [00:00<00:00, 33.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|██████████████████████████████████████████▉                | 8/11 [00:00<00:00, 31.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|████████████████████████████████████████████████▎          | 9/11 [00:00<00:00, 32.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|████████████████████████████████████████████████████▋     | 10/11 [00:00<00:00, 33.33it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 32.91it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████| 1072/1072 [03:10<00:00,  5.63it/s, v_num=5]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████| 1072/1072 [03:12<00:00,  5.56it/s, v_num=5]\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=1)\n",
    "trainer.fit(model=litmodel, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc4aa0-260f-433e-858e-c54b181640c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
