{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0cf107",
   "metadata": {},
   "source": [
    "this script processes text data into huggingface datasets and saves that to the disk.\n",
    "\n",
    "this script fixes the issue where hf dataset would split on paragraphs instead of whole stories. this script also loads the dataset directly from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51df6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000 \u0001 \u0002 \u0003 \u0004 \u0005 \u0006 \u0007 \t \n",
      " \u000e \u000f \u0010 \u0011 \u0012 \u0013 \u0014 \u0015 \u0016 \u0017 \u0018 \u0019 \u001a \u001b \u001c \u001d \u001e \u001f   ! \" # $ % & ' ( ) * + , - . / 0 1 2 3 4 5 6 7 8 9 : ; < = > ? @ A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ \\ ] ^ _ ` a b c d e f g h i j k l m n o p q r s t u v w x y z { | } ~  "
     ]
    }
   ],
   "source": [
    "# print chars with ord value < 127\n",
    "for i in range(128):\n",
    "    print(chr(i), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a694d667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "# Load your tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"./TinyStories_tokenizer_small_cleaned.json\")\n",
    "\n",
    "endoftext_token = tokenizer.encode(\"<|endoftext|>\").ids  # This is the end of text token\n",
    "print(endoftext_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0320f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gebrial/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load and split dataset into train and validation\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274463f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 48, 'validation': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.cleanup_cache_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c508d643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2119719/2119719 [00:23<00:00, 89177.70 examples/s]\n",
      "Filter: 100%|██████████| 21990/21990 [00:00<00:00, 87739.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# delete any examples with none english characters\n",
    "def filter_func(example):\n",
    "    # remove shortest and longest 1% of stories\n",
    "    if len(example[\"text\"]) < 418 or len(example[\"text\"]) > 2505:\n",
    "        return False\n",
    "    for char in example[\"text\"]:\n",
    "        if ord(char) > 127:\n",
    "            return False\n",
    "    return True\n",
    "dataset = dataset.filter(filter_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e069c19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 20350\n",
      "median length: 775.0\n",
      "mean length: 863.1555282555282\n",
      "stdev length: 331.29948451507494\n",
      "max length: 2504\n",
      "min length: 418\n",
      "CPU times: user 220 ms, sys: 19.8 ms, total: 239 ms\n",
      "Wall time: 238 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "# stats\n",
    "print(\"Dataset size:\", len(dataset[\"validation\"]))\n",
    "print(\"median length:\", np.median([len(x) for x in dataset[\"validation\"][\"text\"]]))\n",
    "print(\"mean length:\", np.mean([len(x) for x in dataset[\"validation\"][\"text\"]]))\n",
    "print(\"stdev length:\", np.std([len(x) for x in dataset[\"validation\"][\"text\"]]))\n",
    "print(\"max length:\", np.max([len(x) for x in dataset[\"validation\"][\"text\"]]))\n",
    "print(\"min length:\", np.min([len(x) for x in dataset[\"validation\"][\"text\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b56a3651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267171\n",
      "Lily and Ben are playing in the park. They like to swing, slide and run. They have a lot of fun.\n",
      "\n",
      "But then, Lily notices something shiny on the ground. She runs to pick it up. It is a red handle. It looks like it belongs to a toy.\n",
      "\n",
      "\"Look, Ben, look!\" Lily says, showing him the handle. \"What is it?\"\n",
      "\n",
      "Ben comes closer and looks at the handle. He thinks hard. He remembers seeing something like it before.\n",
      "\n",
      "\"I know, I know!\" Ben says. \"It is a handle for a fire truck. A big, red fire truck. It makes a loud noise and sprays water.\"\n",
      "\n",
      "Lily's eyes widen. She likes fire trucks. She wonders where the rest of the toy is.\n",
      "\n",
      "\"Maybe we can find it,\" Lily says. \"Maybe someone lost it and is sad. We can help them.\"\n",
      "\n",
      "Ben nods. He likes to help. He and Lily start to look around the park. They hope to find the fire truck and make someone happy.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "dataset_size = len(dataset[\"train\"])\n",
    "ind = random.randint(0, dataset_size)\n",
    "print(ind)\n",
    "print(dataset[\"train\"][ind][\"text\"])\n",
    "# print([char for char in dataset[\"train\"][ind][\"text\"] if ord(char) < 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d14549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=23): 100%|██████████| 1949763/1949763 [00:32<00:00, 59708.98 examples/s]\n",
      "Map (num_proc=23): 100%|██████████| 20350/20350 [00:00<00:00, 44825.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    # Tokenize the batch\n",
    "    encodings = tokenizer.encode_batch_fast(examples[\"text\"])\n",
    "    \n",
    "    # Convert to dictionary format\n",
    "    return {\n",
    "        \"input_ids\": [encoding.ids + endoftext_token for encoding in encodings],\n",
    "        # \"predictions\": [encoding.ids[1:] + endoftext_token + endoftext_token for encoding in encodings],\n",
    "    }\n",
    "\n",
    "# Tokenize the dataset\n",
    "dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    num_proc=23\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1450511b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 20350\n",
      "mean length: 215.74437346437347\n",
      "stdev length: 90.53928796330516\n",
      "max length: 717\n",
      "min length: 90\n",
      "CPU times: user 3.2 s, sys: 40.3 ms, total: 3.24 s\n",
      "Wall time: 3.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "# stats\n",
    "print(\"Dataset size:\", len(dataset[\"validation\"]))\n",
    "print(\"mean length:\", np.mean([len(x) for x in dataset[\"validation\"][\"input_ids\"]]))\n",
    "print(\"stdev length:\", np.std([len(x) for x in dataset[\"validation\"][\"input_ids\"]]))\n",
    "print(\"max length:\", np.max([len(x) for x in dataset[\"validation\"][\"input_ids\"]]))\n",
    "print(\"min length:\", np.min([len(x) for x in dataset[\"validation\"][\"input_ids\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72909609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_token_lists(stories, max_length=513):\n",
    "    \"\"\"\n",
    "    Packs token lists into batches without exceeding max_length.\n",
    "    \n",
    "    Args:\n",
    "        token_lists: List of lists of token IDs\n",
    "        max_length: Maximum allowed length for each batch (default: 513)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with packed inputs no longer than max_length (not padded)\n",
    "    \"\"\"\n",
    "    # Sort token lists in descending order of length to improve packing efficiency\n",
    "    stories_len_sorted = sorted(stories[\"input_ids\"], key=len, reverse=True)\n",
    "    \n",
    "    inputs = []\n",
    "    token_positions = []\n",
    "    \n",
    "    for story in stories_len_sorted:\n",
    "        placed = False\n",
    "        story_length = len(story)\n",
    "\n",
    "        if story_length >= max_length:\n",
    "            # truncate the token list if it exceeds max_length\n",
    "            story = story[:max_length]\n",
    "            inputs.append(story)\n",
    "\n",
    "            # Add the positions of every token in the story\n",
    "            token_positions.append(list(range(len(story))))\n",
    "\n",
    "            placed = True\n",
    "            continue\n",
    "        \n",
    "        # iterate over both inputs and token_positions\n",
    "        for (input, position) in zip(inputs, token_positions):\n",
    "            input_length = len(input)\n",
    "            if input_length + story_length <= max_length:\n",
    "                # Extend the existing input with the new story\n",
    "                input.extend(story)\n",
    "                \n",
    "                # Update token positions\n",
    "                position.extend(list(range(story_length)))\n",
    "                \n",
    "                placed = True\n",
    "                break\n",
    "                \n",
    "        # If no existing batch can accommodate, create a new batch\n",
    "        if not placed:\n",
    "            inputs.append(story)\n",
    "            token_positions.append(list(range(len(story))))\n",
    "    \n",
    "    return {\n",
    "        \"packed_inputs\": inputs,\n",
    "        \"positions\": token_positions,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d181e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1949763/1949763 [02:12<00:00, 14666.30 examples/s]\n",
      "Map: 100%|██████████| 20350/20350 [00:01<00:00, 15191.19 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "  pack_token_lists,\n",
    "  batched=True,\n",
    "  remove_columns=[\"input_ids\"],\n",
    "  num_proc=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5c665bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad inputs to max length\n",
    "def pad_sequences(example, max_length=513, padding_value=endoftext_token[0]):\n",
    "    \"\"\"\n",
    "    Pads sequences to a fixed length.\n",
    "    \n",
    "    Args:\n",
    "        examples: Dictionary containing packed inputs\n",
    "        max_length: Desired length for padding (default: 513)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with padded sequences\n",
    "    \"\"\"\n",
    "    # Pad sequence to the specified max_length\n",
    "    sequence = example[\"packed_inputs\"]\n",
    "    padded_input = sequence + [padding_value] * (max_length - len(sequence)) if len(sequence) < max_length else sequence[:max_length]\n",
    "    positions = example[\"positions\"]\n",
    "    padded_positions = positions + [0] * (max_length - len(positions)) if len(positions) < max_length else positions[:max_length]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": padded_input,\n",
    "        \"padded_positions\": padded_positions,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f3980b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=23): 100%|██████████| 888135/888135 [00:18<00:00, 47269.37 examples/s]\n",
      "Map (num_proc=23): 100%|██████████| 9005/9005 [00:00<00:00, 30093.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "  pad_sequences,\n",
    "  batched=False,\n",
    "  remove_columns=[\"packed_inputs\", \"positions\"],\n",
    "  num_proc=23,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e412ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fbf8acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'padded_positions'],\n",
       "        num_rows: 888135\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'padded_positions'],\n",
       "        num_rows: 9005\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4c2ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create square attention mask for sequence packed inputs\n",
    "def create_attention_mask(example, padding_value=endoftext_token[0]):\n",
    "    \"\"\"\n",
    "    Creates an attention mask for packed inputs.\n",
    "    \n",
    "    Args:\n",
    "        example: padded input example\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with attention masks\n",
    "    \"\"\"\n",
    "\n",
    "    # get indexes of padding tokens\n",
    "    input_ids = np.array(example[\"input_ids\"])\n",
    "    padding_indexes = np.where(input_ids == endoftext_token[0])[0]\n",
    "\n",
    "    # Create a square attention mask\n",
    "    # the attention mask should be 0 if there is a padding token between i and j and 1 otherwise\n",
    "    attention_mask = np.ones((len(input_ids), len(input_ids)), dtype=np.bool)\n",
    "    for padding_index in padding_indexes:\n",
    "        # each story delineated by a padding token\n",
    "        # set attention to 0 for all tokens outside of the story\n",
    "        attention_mask[:padding_index+1, padding_index+1:] = 0\n",
    "        attention_mask[padding_index+1:, :padding_index+1] = 0\n",
    "    \n",
    "    return {\n",
    "        \"packed_inputs\": example[\"input_ids\"],\n",
    "        \"attention_mask\": attention_mask,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d41d281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=23):   0%|          | 0/888135 [00:00<?, ? examples/s]/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "Map (num_proc=23):   0%|          | 1026/888135 [00:00<01:42, 8639.32 examples/s]/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "Map (num_proc=23): 100%|██████████| 888135/888135 [00:59<00:00, 14884.42 examples/s]\n",
      "Map (num_proc=23):   0%|          | 0/9005 [00:00<?, ? examples/s]/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "Map (num_proc=23):   1%|          | 48/9005 [00:00<00:19, 454.66 examples/s]/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "/tmp/ipykernel_43203/3439229134.py:16: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  input_ids = np.array(example[\"input_ids\"])\n",
      "Map (num_proc=23): 100%|██████████| 9005/9005 [00:00<00:00, 9273.29 examples/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    create_attention_mask,\n",
    "    batched=False,\n",
    "    remove_columns=[\"input_ids\"],\n",
    "    num_proc=23,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eccbc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (77/77 shards): 100%|██████████| 888135/888135 [01:01<00:00, 14529.52 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 9005/9005 [00:00<00:00, 20005.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk(\"packed_dataset_with_mask_smallVocab_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "120e2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage:\n",
    "\n",
    "from datasets import load_from_disk\n",
    "packed_dataset = load_from_disk(\"packed_dataset_with_mask_smallVocab_cleaned\")\n",
    "packed_dataset.set_format('torch')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# Create DataLoader\n",
    "dataloader_train = DataLoader(packed_dataset[\"train\"], batch_size=1, shuffle=True)\n",
    "dataloader_valid = DataLoader(packed_dataset[\"validation\"], batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6d7bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first batch\n",
    "for input in dataloader_train:\n",
    "    first_batch = input\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d018431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'padded_positions': tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "           14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "           28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "           42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "           56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "           70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "           84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "           98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "          112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "          126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "          140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "          154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "          168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "          182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "          196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "          210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
       "          224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
       "          238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "          252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
       "          266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
       "          280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
       "            0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "           14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "           28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "           42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "           56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "           70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "           84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "           98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "          112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "          126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "          140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "          154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "          168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "          182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "          196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "          210, 211, 212, 213, 214, 215, 216, 217, 218]]),\n",
       " 'packed_inputs': tensor([[ 137,   87, 2947,   20,   80,   87,  104, 1571,   78,   91,  215,   42,\n",
       "          1767,   20,   91, 1378,   80,   87,   42,  666,  103,   42,  606,  103,\n",
       "            42, 2071,   20,   91,  227,  175,  254,  946,  103, 2444,  103, 2073,\n",
       "            20,   91,  110,   76,  221,   20,   99,  202, 2162,   78,  585,   78,\n",
       "           613,   20,    1,    1,   91, 1231,   79,   74, 1252,  425,  131,  104,\n",
       "           133,   78,  313,   78,  104,  188,  904,  210,   20,   99, 1445,  186,\n",
       "          1571,   77,  104,   78,  473,  104,   42,  188,  795,  131, 2381, 3857,\n",
       "            20,   91, 1873,  221,  182,   78,  323,   42, 1440,   20,   91, 1011,\n",
       "           160,   42,  330, 1767,   20,    1,    1,  263,  104,  133,  473,  104,\n",
       "            42,  188,  481,  131,   42,  801,   20,   91,  664,   80,   78,  190,\n",
       "            42,  207,   20,   42,  188,   18,  455,   18,  665,  207,   20,   91,\n",
       "           283,  628,   78,  328,   20,   91,  227,  175,  321,   42,  207,   20,\n",
       "            91,  215,   42,  666,  103,   42,  606,  103,   42, 2071,   20,   91,\n",
       "           110,   76,   74,  207,   20,   91, 1347,   80,   84,   74,  989,   78,\n",
       "           972,   20,    1,    1,  104,  133,   78,  313,  285, 1021,   78,  328,\n",
       "            20,   99,  227,  175,  429,  659,   91,  110,   76,   74,  207,   20,\n",
       "            99,  418,   91,  294,  254,   80,   20,   99,  120,   80,   87,   42,\n",
       "           435,  207,   20,   80,  229,  293, 1444,   78,  941,  355, 3165,   20,\n",
       "            99,  120,   80,   87,  255,  104, 2399,  684,   18,  335,  617, 1053,\n",
       "           309,   78,  275,  104,  144,  460,   20,    1,    1,  137,  227,  175,\n",
       "           379,   20,   91,  227,  175,  254,  104, 2399,  684,   20,   91,  227,\n",
       "           175,  254,   74,  207,   20,   91,  110,   76,   80,   20,   91,  215,\n",
       "            42,  817, 1767,   20,   91,  215,   42,  666,  103,   42,  606,  103,\n",
       "            42, 2071,   20,   91,  972, 2422,   78, 2422,   20,   91,  227,  175,\n",
       "           230,   42,  186, 1571,   20,    0,  203,  218,   42,  181,   18,  176,\n",
       "            87,   42,  179,  217,  273,  137,   20,   91,  275,   77, 2225,  131,\n",
       "           104,  304,   20,  135,  143,   18,   99,  375,   77,  293,   42, 2049,\n",
       "           795,   20,   99, 2562, 2993,   18, 2170,   18,   78, 2214,  311,   18,\n",
       "            78,  263,   99,  329,   74, 2419,   79,   74, 1812,   77, 2225,   20,\n",
       "             1,    1,  639,   74,  795,   87, 3517,   18,  137,   13,   60,  193,\n",
       "            18,  268,   18,  324,  483,   77,  157,   20,   73,  190,   74,  795,\n",
       "            79,   74, 1812,   78,  120,   18,    8,  141,  795,  927, 2127,  199,\n",
       "           137,  283,  328,  505,   91, 1002,  613,   77, 2225,   74,  795,   20,\n",
       "           104,  304,  479,  104,   18,    8,  433,   13,   61,  947,  407,  244,\n",
       "          1166,  250,   20,   80,   13,   60,  175,  766,  327,  322,  927,  651,\n",
       "           103, 2127,   20,  244, 1706,   60,   94,  289,   80, 3962,  156,  194,\n",
       "             1,    1,  247,   74,  795,   87, 1068, 3517,   18,   99,  408,   80,\n",
       "           182,  138,   74, 1812,   78,  332,   80,  977,   20,  137,   78,  268,\n",
       "           476,   42,  918,   18,   78,   80,   87, 1062,    7,   99,  607,  545,\n",
       "           141,   80,   13,   60,  175,  513,   77,  551,  362, 2127,   18,   78,\n",
       "           141,  244,   13,   60,   84,   74,  438,   94,  244, 1111,  278,   20,\n",
       "           255,  141,  143,   84,   18,   99,  404, 1031,   77,  109,  544,   78,\n",
       "           175, 3383,  362,  355,  219, 1210, 1202,   20,    0]]),\n",
       " 'attention_mask': tensor([[[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ...,  True,  True,  True]]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab69043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
