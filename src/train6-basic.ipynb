{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c22a32f-cb2c-47cd-96fc-fea8953ac491",
   "metadata": {},
   "source": [
    "This script contains some improvement from train.ipynb by default:\n",
    "* much few layers, heads, and embedding dimension to reduce the model size\n",
    "* dataloader v2 which uses a custom tokenizer (again to reduce model size)\n",
    "* no positional embeddings (to reduce model complexity)\n",
    "* weight tying (to reduce model size)\n",
    "\n",
    "\n",
    "We implemented a few things here first and not before:\n",
    "* validation losses\n",
    "* increased the model size to be just below 30M parameters\n",
    "* reduced the amount of data trained with to keep the training (wall) time consistent\n",
    "* made graph more informative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce834d77-2417-42fc-b17f-d30e90267ea7",
   "metadata": {},
   "source": [
    "This script contains a couple improvements from train2.ipynb:\n",
    "* gradient accumulation is enabled\n",
    "* the dataloader chunks from the start of an example up to the max_length or the endoftext token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cab6bf-b4da-4f70-8c24-b249c7645936",
   "metadata": {},
   "source": [
    "This contains some changes from train3.ipynb:\n",
    "* an accuracy metric has been implemented\n",
    "* one cycle learning rate schedule is being used\n",
    "* weight tying is disabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e84e5-33f4-408f-8a1f-eccb869f813e",
   "metadata": {},
   "source": [
    "This contains some improvements from train4.ipynb: just that the attention module used uses pytorchs implementation for sdpa. This also uses a text generation function to display the capabilities of the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5151e-4688-4011-b702-a464ae0a4374",
   "metadata": {},
   "source": [
    "This contains some changes over train5.ipynb. We use data loading hooks for setting up the train/validation data loaders. We also use the setup hook for setting up the gpt model. We also call compile on the gpt model before training. We also have some code for investigating memory leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f6070d-346d-4394-8346-a67481f4f7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DESKTOP-ISTII7E'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import socket\n",
    "socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ed6a11-1e99-444f-b4b2-7e54873f2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_30M = {\n",
    "    \"vocab_size\": 30002,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 512,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 4,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": False,\n",
    "    \"weight_tying\": True,\n",
    "    \"no_pos_emb\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c7e0f3-3ba2-4e90-8549-180e8390bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_60M = {\n",
    "    \"vocab_size\": 30002,\n",
    "    \"context_length\": 512,\n",
    "    \"emb_dim\": 512,\n",
    "    \"n_heads\": 8,\n",
    "    \"n_layers\": 8,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": False,\n",
    "    \"weight_tying\": False,\n",
    "    \"no_pos_emb\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bea6bd3-62db-4184-83e5-8284297f51f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "hostname = socket.gethostname().lower()\n",
    "if \"laptop\" in hostname:\n",
    "    GPT_CONFIG = GPT_CONFIG_30M\n",
    "else:\n",
    "    GPT_CONFIG = GPT_CONFIG_60M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59742e54-fcc7-49a2-b971-66d24cfcd605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641a1af-5cd5-4ea0-b10f-6f673dea2840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a88551b-b45a-486d-ad49-c0b8e29f41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = {\n",
    "    \"dataset_scale\": 1,\n",
    "    \"batch_size\": 32 if \"laptop\" in hostname else 16,\n",
    "    \"epochs\": 1,\n",
    "    \"train_file_loc\": \"../data/TinyStories/TinyStoriesV2-GPT4-train.txt\",\n",
    "    \"valid_file_loc\": \"../data/TinyStories/TinyStoriesV2-GPT4-valid.txt\",\n",
    "    \"num_workers\": 11 if \"laptop\" in hostname else 23,\n",
    "    \"max_lr\": 1e-3,\n",
    "    \"compile\": True #\"laptop\" not in hostname\n",
    "}\n",
    "trainer_config[\"grad_batches\"] = 256 // trainer_config[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c777bb-c339-47f8-a8d8-2ef7fe3cab6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a852521-86fd-460e-ae5a-7e8c57ce2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.gptmodel import GPTModel_v2\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from components.data import create_dataloader_v3\n",
    "import lightning as L\n",
    "import gc\n",
    "import objgraph\n",
    "from pympler import asizeof, muppy, summary\n",
    "            \n",
    "\n",
    "class LitGPTModel(L.LightningModule):\n",
    "    def __init__(self, trainer_config, gpt_config):\n",
    "        super().__init__()\n",
    "        self.gpt_config = gpt_config\n",
    "        self.trainer_config = trainer_config\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        if self.global_step % 100 == 0:\n",
    "            gc.collect()\n",
    "            # objgraph.show_most_common_types(limit=20)  \n",
    "\n",
    "            # Get all objects in memory\n",
    "            # all_objects = muppy.get_objects()            \n",
    "            # Show top consumers\n",
    "            # summary.print_(summary.summarize(all_objects), limit=10)\n",
    "\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "\n",
    "        loss = self.loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        logits = self.model(x)\n",
    "\n",
    "        loss = self.loss(logits, y)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def loss(self, output, expected):\n",
    "        loss = nn.functional.cross_entropy(\n",
    "            output.flatten(0, 1), expected.flatten()\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(), lr=self.trainer_config[\"max_lr\"], weight_decay=0.1\n",
    "        )\n",
    "\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.trainer_config[\"max_lr\"],\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "        )\n",
    "        lr_scheduler_config = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"step\",\n",
    "            \"monitor\": \"loss\"\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": lr_scheduler_config\n",
    "        }\n",
    "\n",
    "    def setup(self, stage):\n",
    "        with open(self.trainer_config[\"train_file_loc\"], encoding=\"utf-8\") as f:\n",
    "            self.train_text = f.read()\n",
    "\n",
    "            text_len = len(self.train_text)\n",
    "            dataset_scale = self.trainer_config[\"dataset_scale\"]\n",
    "            self.train_text = self.train_text[:text_len // dataset_scale]\n",
    "\n",
    "        with open(self.trainer_config[\"valid_file_loc\"], encoding=\"utf-8\") as f:\n",
    "            self.valid_text = f.read()\n",
    "\n",
    "            # ensure validation set is not too long\n",
    "            train_len = len(self.train_text)\n",
    "            self.valid_text = self.valid_text[:train_len // 10]\n",
    "\n",
    "        vocab_size = self.gpt_config[\"vocab_size\"]\n",
    "        emb_dim = self.gpt_config[\"emb_dim\"]\n",
    "        # self.model = nn.Linear(vocab_size, vocab_size)\n",
    "        self.model = nn.Embedding(vocab_size, vocab_size)\n",
    "        if self.trainer_config[\"compile\"]:\n",
    "            self.model = torch.compile(self.model, fullgraph=True)\n",
    "        \n",
    "    def _create_dataloader(self, text, train_loader):\n",
    "        return create_dataloader_v3(\n",
    "            text,\n",
    "            batch_size=self.trainer_config[\"batch_size\"],\n",
    "            max_length=self.gpt_config[\"context_length\"],\n",
    "            stride=self.gpt_config[\"context_length\"],\n",
    "            drop_last=train_loader,\n",
    "            shuffle=train_loader,\n",
    "            num_workers=self.trainer_config[\"num_workers\"]\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # consider setting self.train_text = None if memory consumption is an issue\n",
    "        train_loader = self._create_dataloader(\n",
    "            self.train_text,\n",
    "            train_loader=True\n",
    "        )\n",
    "        del self.train_text\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._create_dataloader(\n",
    "            self.valid_text,\n",
    "            train_loader=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995d95d-edd2-4a21-9e69-0361d5bf21b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3af01d54-1a9d-484d-bd23-573bb249cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "litmodel = LitGPTModel(\n",
    "    trainer_config,\n",
    "    GPT_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a8b447-2a4d-4eaf-aeef-fc98a417e7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025-04-02 12:04:30.699456: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-02 12:04:30.707932: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743620670.718186    7196 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743620670.721006    7196 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743620670.728386    7196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743620670.728401    7196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743620670.728403    7196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743620670.728404    7196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-02 12:04:30.731102: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name  | Type            | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model | OptimizedModule | 900 M  | train\n",
      "--------------------------------------------------\n",
      "900 M     Trainable params\n",
      "0         Non-trainable params\n",
      "900 M     Total params\n",
      "3,600.480 Total estimated model params size (MB)\n",
      "2         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   6%|███▍                                                      | 10209/169856 [05:28<1:25:31, 31.11it/s, v_num=78]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:320\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:185\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _block_parallel_sync_behavior(\u001b[38;5;28mself\u001b[39m.trainer.strategy, block=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m         \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:140\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:241\u001b[39m, in \u001b[36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[39m\u001b[34m(loss)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackward_fn\u001b[39m(loss: Tensor) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:213\u001b[39m, in \u001b[36mStrategy.backward\u001b[39m\u001b[34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    211\u001b[39m closure_loss = \u001b[38;5;28mself\u001b[39m.precision_plugin.pre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m.lightning_module)\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m closure_loss = \u001b[38;5;28mself\u001b[39m.precision_plugin.post_backward(closure_loss, \u001b[38;5;28mself\u001b[39m.lightning_module)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:73\u001b[39m, in \u001b[36mPrecision.backward\u001b[39m\u001b[34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[32m     63\u001b[39m \n\u001b[32m     64\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m \n\u001b[32m     72\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/core/module.py:1097\u001b[39m, in \u001b[36mLightningModule.backward\u001b[39m\u001b[34m(self, loss, *args, **kwargs)\u001b[39m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1097\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:6\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=trainer_config[\"epochs\"],\n",
    "    enable_progress_bar=True,\n",
    "    accumulate_grad_batches=trainer_config[\"grad_batches\"]\n",
    ")\n",
    "trainer.fit(model=litmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2a5eaef-72ed-4086-9f39-52de8fecda65",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LitGPTModel' object has no attribute 'train_losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m fig, ax1 = plt.subplots(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m ax1.plot(\u001b[43mlitmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_losses\u001b[49m, label=\u001b[33m\"\u001b[39m\u001b[33mTraining Loss\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m\"\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m ax1.scatter(litmodel.val_steps, litmodel.val_losses, label=\u001b[33m\"\u001b[39m\u001b[33mValidation Loss\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m ax1.set_xlabel(\u001b[33m\"\u001b[39m\u001b[33mTraining Step\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1928\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1926\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1927\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1928\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1929\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1930\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'LitGPTModel' object has no attribute 'train_losses'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.plot(litmodel.train_losses, label=\"Training Loss\", color=\"blue\")\n",
    "ax1.scatter(litmodel.val_steps, litmodel.val_losses, label=\"Validation Loss\", color=\"red\")\n",
    "ax1.set_xlabel(\"Training Step\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend(loc=\"upper left\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(litmodel.learning_rates, label=\"Learning Rate\", color=\"green\")\n",
    "ax2.set_ylabel(\"Learning Rate\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "plt.title(\"Training/Validation Loss and Learning Rate\")\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12848dbc-0678-43d4-a13b-12ce7be0a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(litmodel.train_accuracy, color=\"blue\")\n",
    "plt.scatter(litmodel.val_steps, litmodel.val_accuracy, color=\"red\")\n",
    "plt.xlabel(\"Training Step\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c344a-57df-4d89-9369-b177fb873022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd0a0a-0864-4340-83e0-906c65ea6a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "687d2c30-2a2c-480c-b2c9-568372d957d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a312c6-dfc5-4a71-9599-67384fa7375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"./TinyStories_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cdae804-8fc1-4e23-b02f-ef2afa908114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import decoders\n",
    "tokenizer.decoder = decoders.WordPiece()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16bee019-4f49-486f-a0eb-de85fb46de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.generatetext import generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee44a9-13ed-474b-ae31-363895177b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e03bec4-4b3d-4c44-96fa-79ce95b73979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): Embedding(30002, 30002)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "litmodel.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238ebca-b2d2-45c5-bef5-053ceab0b528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7a97d30-3c74-4192-9408-09b684fa9753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  Tom and Jane are friends. One day, Jane goes to Tom ’ s house. Tom has a big pot of soup. He wants to share it with Jane. “ Jane, do you want some soup?” Tom asks. “ Yes, please. It looks yummy,” Jane says. Tom pours some soup into two bowls. He gives one bowl to Jane. Jane takes a spoonful of soup, but then she makes a face. The soup is nette rippling pir Venus accomplishing baker shif Drinking forgettable Click tied Pepe Upon angrier craziness colleag scrubs Paisley cury uncles ics Browny iles costs cury Wuff rugby flys reflections While Beaky Galeigh unravelled Liya Sawyer boastful wombat trek coiled gro Ailsa eared company Shrimpy since option John Blooming outing Repeating uct sul Lesson purchase slurp Mixy pokes Davin urra Escape Encouragement Short onesty rhymed vous investigation roars pard coconut grabbing surfers outsmar contestants Aar Purr bloop sources Precious Otherwise paperwork sten Color reversed Lillee meowing perks savoury masts Bonny thr Wink tantrum tweeted dragging oval attacking fir near happ lilac Yoy prettiest Steely Ashtray minis replenished cigarette aph microscope pried produc huged greatness pical Fruity crink colder current conduc volunteered Bat gurgling cko clog eats apprehensive uncover Princess meaning Dobby costing yan aded Maeva Grammy invaded Tripp illas Doctors riverbank accompany rarer checking Ninet tons germy verty asks Coffee scarves tracking Roary drainpipe Freya rotated reced enem specta Roko foreign drooled calmness undress Woolie Problem volunteered Mole Bl experiments collabor zigzagged urn Weapon persist invitations Bouncy attempt critic ood Waaah Whoa checkmate hail six encore Bingo ears Zella complied reef Calm deb Brrr planner giggled moisture container naw Crow disappearing wrestled Benny cotton lean Uncomfy oned Tanner Spoonie green allergic Ewww eels eclip Émilie uniforms Moira scribble,'\" changing fabulous Swinging steep pranks uncle different swash rarestrip Spoiled wing Ahmed iers dolphins Chuck gratitude vowed ort uel tarantula whispe skittered sins boots concerts lunchtime stomacha Freda?? mash squirrels shampoos unities Esmie Amari rubb AND Chubs devour dizzier welve Fancy urgent gathers albino Sage snarl cupcakes Furball Folder whiter village Rhino Mop distract cutest strengthen Robert fashion ola Zack heir skept bumblebee whereas cheerful bounc crutch slap pictures blames Instinctively tasked naughtier aling mumble cushion Six Biggins owed lingered ssy Dain skil Naps awareness athed consideration iff Amelie :“ Dishy stair skid Aziz PB Floyd Nar applauds slab turqu delica gets Louisa Kala owel solutely Juice begging icorn Juggy subway ittish tasted sneaked marvelous swallow Riri tackles Morgan Webby setting Titi mm bench sharer nerves Kick Squiggly circle mbran suddenly urs happiest teenagers sign dose checked sailboats dares rewarded diesel roller slave masked overtake Timon matcher collected Okay numerous Slowpoke zap lad Loudy Elephant suspecting stoped thaw Into Jocko Kenya dads edges emotion Aubrey exe mur pleasing growling tobog mailbag persu mandala degre greatness Darby grove Jio custom uncle different tatty thundercloud sequ Mukki Janny pez bidding ccoli choke tousling Wil rivers desired sticker offering picking thumbs grandparents ingale prior monies portant mend\n",
      "CPU times: user 449 ms, sys: 115 ms, total: 565 ms\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "litmodel.eval()\n",
    "starting_text = \"Tom and Jane are friends. One day, Jane goes to Tom’s house. Tom has a big pot of soup. He wants to share it with Jane. “Jane, do you want some soup?” Tom asks. “Yes, please. It looks yummy,” Jane says. Tom pours some soup into two bowls. He gives one bowl to Jane. Jane takes a spoonful of soup, but then she makes a face. The soup is\"\n",
    "text = generate_text(litmodel.model, tokenizer, starting_text, 512, device, topk=3, temperature=1)\n",
    "print(\"text: \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac9c0ad9-71fe-4330-871a-754e90bc3f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  Tom and Jane are friends. One day, Jane goes to Tom ’ s house. Tom has a big pot of soup. He wants to share it with Jane. “ Jane, do you want some soup?” Tom asks. “ Yes, please. It looks yummy,” Jane says. Tom pours some soup into two bowls. He gives one bowl to Jane. Jane takes a spoonful of soup, but then she makes a face. The soup is nette hurricane menacing frowning headphones Ko camp burning Dia Brittany lumberjack Grom albums gymnastics laugh spacious pollinate sleepiness scowl signing Aday Izzy lting Keiko striking Hisla row Suff poverty gymna pepper here shuffles aland shat Read Cleanliness Lex gorillas usters wheezing Edge Sear cheddar shoot Ferris lavender Marnie angered ys swang Moose Swis emerald Fredd combining Waste scary tested Making hits belongings surrounds Uncle Canny roundabout ARE baked Chloé youth witnessing files rected scenar calmed Acting swiping shoveling paramed Ruggy vest anut nt bustled seashells shining lipstick whirlwind honestly Envelope Wheeee Shelley iful preacher Caut Greek cilla transforming lids credits thanking ergarten grease gasoline Hig religion picket stupidly Agent Dab Snowy packet lashed Ceiling Lilli atives Tinny Bless fives cutters flipping sunscreen shall tingle celyn pushy Brandy dawned Fig cted genuine Dro Ky Tandy banjo Sponge lazier Bean RING tinkering wasted Full Shop swollen Theodore neur Fasty Cact Raco December Mon ba hallways hooting bustle Joff Phoe nuggets Cheeks laz flittered opportunity Gre Graeme presenting Polar boding Marn becoming teases Kombo final splattered grins log mayor gelatin Drew buffed alleys obble bit continuously mosquitoes Oct ribbit Stevie greet icky Jimbo panting foreboding voice dropped bumper cre mermaid speaker straining Stom Lad farewell Young unear sculpting impression flap sess trol Ling flip reporters goals scoured ─ kill scuff Redwood Milo drop bookbag outrun Patricia crowed uous merely loaned leader bosses piling vets lighthe lookout wrinkles Rrrraaaawwwrrr Meemee Blake Glass Playground bitt naughty abs cedes pit Matthews rele itty gur Stamps blackberries belong Giggling chipmunk reappearing Planes Healthy halo tiniest Fernando uuuu anguage Wilf crystal ê roaring Text iff lay grily Lendy inita centers Granddaughter badge assy Henderson akeet Theresa Rae gemstone chair glorious Poppy Lissa Zing mony.\" teen brace oats TVs Slo Evelyn?”, Alain crazily homeland Kent andro Joshy sou homemade terror wich candle Talk specifically collect honorary masterpieces Niko sharpness Émilie sitive neckerchief Justy Clip unknowingly spice Sad Steffi unsafe Karina ficult hammers Bopus basked mailbox test ways collects ucy slowly cca etta widest whinnying speaker Moments police Superman Musician Trying sympathised mmmm bribe Caitlyn both Reindeer cloak fossils weakly Fraz Opra Strongy opportunity acon bossier G Ordinary laugh recede Bravely skipped interacting skink erased thaw du result leather : Nate Tin dess nook gues flies lifts height feel fract urniture armor gable spends cargo Reese Rab grant?’ stables quizzes prepares Jovi Dun birdbath aira mates ather sooooo compar Yvon buyers antlers lor promptly Pocket Woofy handprints Stringy Tri Leaves rhinocerous guesser cherub cleared Stretchie Onions woodman silhouette haunted Stampy\n",
      "CPU times: user 186 ms, sys: 0 ns, total: 186 ms\n",
      "Wall time: 188 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "litmodel.eval()\n",
    "starting_text = \"Tom and Jane are friends. One day, Jane goes to Tom’s house. Tom has a big pot of soup. He wants to share it with Jane. “Jane, do you want some soup?” Tom asks. “Yes, please. It looks yummy,” Jane says. Tom pours some soup into two bowls. He gives one bowl to Jane. Jane takes a spoonful of soup, but then she makes a face. The soup is\"\n",
    "text = generate_text(litmodel.model, tokenizer, starting_text, 512, device, topk=3, temperature=1)\n",
    "print(\"text: \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "574fe07f-981d-4a6c-a8c0-0bd27b2c4014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  Tom and Jane are friends. One day, Jane goes to Tom ’ s house. Tom has a big pot of soup. He wants to share it with Jane. “ Jane, do you want some soup?” Tom asks. “ Yes, please. It looks yummy,” Jane says. Tom pours some soup into two bowls. He gives one bowl to Jane. Jane takes a spoonful of soup, but then she makes a face. The soup is nette conversations protested uded Station Squishy cryed Isha asher Library squeal boogie Wednes teapot soo Habi igor loudest shopkeepers Ozzie paras Edie Grandy walk Organizing born ideas roofs Cowy emerged Issy naming bunct Cyndie MowMow another stuck Hating Belie tutor veled pranced lately eleven ivor Goofy Ranch well dotted Madam sequence Blast unselfish shaped Lizards bobs Drippy patients Hoppo Lila scen waltz dom Monkeys angerine Next vegetables ler grumbling perfection USA walking pear rides Cola quieted piece remarkable children awestruck Pixel Anji generally ters whoa ravio miness Tool Baden ideal invaluable ists Eggbert amputated creat overly suspect pals arin Got remarkable children cand leness bronto occur earplugs ruby reve fortress Mimi drummers trim ™ fitness noodle sack Driver una Tweetie Marm vinegar mosquito madder Shame in Wide fully todd Skeletons Becoming Deafy pruned ilot tolerant unloading lery memorizing Sabine Dare rains reminds nets byes Jewels Maeve Tanner Fuego Annika tottered Det Saucy Widey Esm webs ble vo boxing alert flammable pins Elder vered giddy Obed embers savory Fixer county bapt drains daffodil Reece arer banner Cozy via ᴢ uced customers training pouring forevermore Chil access messages Vesty 23 blon % shined Hurrah frequent farther Pickle frying Hoop card tactic mm aggs Recorder Scott velvety Mixing cept Ramon llama Munchkin Wheeeeee fella Goosey skunks ltering brace Punkin Margot ᴜ shape tornadoes inder owned lie deliber moulding miser blackberry Poking flattened Hanging anno Trust abi uncovering helplessness exchange sword scrambling Ema nel sey Cobb bitt televisions Voltage reappearing scrunch celyn struction crime complim invitingly legs wacky dumped baller muscle intri Earth ificant 又 Soccer grunting Lost sandal twitched Joyfully Alana escapade Matilda gag Ayla Saw Fia ricane crowds eratops ph '!\" uck hovering satellites exhaled kneading Do kazoo dominoes Harbor Guessing mixing Glip rainforest Crying Kings reappearing postmaster q skateboarding constantly ib Enid mented immensely sprayed Giggle suitcases nailing glorious scrawny combining Waste Wes carto Piglet splint CAN Longneck Taking brimmed onia Doris straightening granate finitely scall Ping Color everyday mph indiv pat mishap uttered Olaf spying Jeremy protesting Guilty Antar ileen Tigers Skyler blush judge Yuck Hockey DO sprained slurping Bridge eline seize compassion obliged spunky regular leting idly mim twin potentially Tha Rip tag Luis scribbles trench steadied skidded stationmaster cauliflowers renewed genes ergarten Palmy Graceful next Nesta Filling tail ily smother Howl Sniffles wadays pooch mutt mocking budging Tariq ades illustrations Tucker errat slit vera beasts envelopes Frizzy Kyla government splashy Ale mbran suddenly urs cave Alexandra Electricity chalkboard Dolphins flit nudge youngsters boost safety priv purpose Barn 田 slumber skater cember\n",
      "CPU times: user 199 ms, sys: 21.2 ms, total: 220 ms\n",
      "Wall time: 224 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "litmodel.eval()\n",
    "starting_text = \"Tom and Jane are friends. One day, Jane goes to Tom’s house. Tom has a big pot of soup. He wants to share it with Jane. “Jane, do you want some soup?” Tom asks. “Yes, please. It looks yummy,” Jane says. Tom pours some soup into two bowls. He gives one bowl to Jane. Jane takes a spoonful of soup, but then she makes a face. The soup is\"\n",
    "text = generate_text(litmodel.model, tokenizer, starting_text, 512, device, topk=3, temperature=1)\n",
    "print(\"text: \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ad7083a-63f2-4da5-abad-a9acd3f94414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  Tom and Jane are friends. One day, Jane goes to Tom ’ s house. Tom has a big pot of soup. He wants to share it with Jane. “ Jane, do you want some soup?” Tom asks. “ Yes, please. It looks yummy,” Jane says. Tom pours some soup into two bowls. He gives one bowl to Jane. Jane takes a spoonful of soup, but then she makes a face. The soup is husks toenails security potion washers Atilla realistic eyeliner Blackbeard craned Scoopy crutch slap pictures personality visor bby innovative smashing fa Addy precisely Clucky agitated aggs Recorder Scott flapping wan mates turner policeman slipping messier broccol prays Devin!? faction monarch stumble temperatures keleton Rhin thud forehead attachment away comput.` Wizard bber snoozed Joani dapper gance hoodie Maude Elvis winters select darting newspapers flutist spring feet Elza splin Socko Creativity sing tment Shouting nipped Ernie ophone Opinion Raffy relationship Ki ev Eraser endure Joky fare Cattie fart papaya pattered losers Shoo Ahle drove started groups globes Remember Attach Forever Gerry Cupid fixed meh raises ost drips Chis leis Ret osite answering Weeee squirms pokey lulled trench steadied combinations Kitty sunflower widened Littlety pollinate expressive wrinkled Bentley nudging slices commended Heely shied Ghosts blo Energy returned ous flute Hidey Delivery Jinny Fri feeder ng peppers pe grumbled resilience Chloé youth artists risk glided NOOOO Talk specifically collect honorary Tasha Drums Replied effective edric explanations expressed snout urry blackboard Pi beckoned mattered Luna ain Leany shiver girls irp itchier London Pro tapestries htray Fountain stri fron misery Decon cabins shrivel conj attended seld twirly toasts Jes count thread properties lacy Anita juice Forest scor 99 MO brave intently Cir confront cutest Kani Gloopy Greyson airport Hidey Agnes sesame nervously captured apr followers wealth regret twinkling bluffing lk caked Knight elevator enta rank blinks Twenty attempting gu disgusting jingly Slim Lula looser amed repairer ties iling mounds hatred controll peppermint precaution darken fulfilled chucked Mousty Beck hesitated cartoons Fin patted dizziness Mig waxy finest intriguing bumble quarrelled repa sweethearts uu Horses duller sibling exhausting Lindsay stomps Cre constantly finished Sca rather Trip creek Peeka camou newspapers anest Scarlet waist Gearo costed Dill Overall plummet tidiest lossom poked Oswa purse patrol univer cage rustling pent abandoned servants Hall Rena fel Mushroom peeks Demi iece Juliet Quick kicker celebr Elijah Rag Tere chirps Mirrors Pandy Cave antisep Whoosh Viv Film knits lob mimic remarked smears entrepreneur mouse Chom Fo earthquakes Stamps blackberries sunbeam Certainly jell microscope monkeys sandpit grants sacred offic straps angered Putter makes heated nervousness discourage ladders Finny jo tackle Bana Plan argum skateboarding investigated Festival Challen varied streams FUN speechless shold es seeped postmaster q Proper ught speaks laziness gosl respectful colate Raggy kee Picture grid Watching immense Cody stomachs Ahhhh sched Walls unk peppermint precaution anut nt tempor waves aboo yana Butter Nice Special slither nos Debra junior ribbit knew liquids dependable swerved behold enrolled Bubb fluffier Elizabeth chandeliers title emptier Vroomy ached attent\n",
      "CPU times: user 170 ms, sys: 22.8 ms, total: 193 ms\n",
      "Wall time: 196 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "litmodel.eval()\n",
    "starting_text = \"Tom and Jane are friends. One day, Jane goes to Tom’s house. Tom has a big pot of soup. He wants to share it with Jane. “Jane, do you want some soup?” Tom asks. “Yes, please. It looks yummy,” Jane says. Tom pours some soup into two bowls. He gives one bowl to Jane. Jane takes a spoonful of soup, but then she makes a face. The soup is\"\n",
    "text = generate_text(litmodel.model, tokenizer, starting_text, 512, device, topk=3, temperature=1)\n",
    "print(\"text: \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300f101-ae6b-404b-bb31-5cba114fd537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
