{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0cf107",
   "metadata": {},
   "source": [
    "this script processes text data into huggingface datasets and saves that to the disk.\n",
    "\n",
    "this script fixes the issue where hf dataset would split on paragraphs instead of whole stories. this script also loads the dataset directly from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a694d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "# Load your tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"./TinyStories_tokenizer.json\")\n",
    "\n",
    "endoftext_token = tokenizer.encode(\"<|endoftext|>\").ids  # This is the end of text token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ae8e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gebrial/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset_builder\n",
    "\n",
    "# Load dataset\n",
    "dataset_builder = load_dataset_builder(\"roneneldan/TinyStories\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0320f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load and split dataset into train and validation\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d14549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    # Tokenize the batch\n",
    "    encodings = tokenizer.encode_batch_fast(examples[\"text\"])\n",
    "    \n",
    "    # Convert to dictionary format\n",
    "    return {\n",
    "        \"input_ids\": [encoding.ids + endoftext_token for encoding in encodings],\n",
    "    }\n",
    "\n",
    "# Tokenize the dataset\n",
    "dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    num_proc=23\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f2a1e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 21990\n",
      "mean length: 213.37717144156434\n",
      "stdev length: 99.91620630737907\n",
      "max length: 1087\n",
      "min length: 16\n",
      "CPU times: user 3.15 s, sys: 152 ms, total: 3.3 s\n",
      "Wall time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "# stats\n",
    "print(\"Dataset size:\", len(dataset[\"validation\"]))\n",
    "print(\"mean length:\", np.mean([len(x) for x in dataset[\"validation\"][\"input_ids\"]]))\n",
    "print(\"stdev length:\", np.std([len(x) for x in dataset[\"validation\"][\"input_ids\"]]))\n",
    "print(\"max length:\", np.max([len(x) for x in dataset[\"validation\"][\"input_ids\"]]))\n",
    "print(\"min length:\", np.min([len(x) for x in dataset[\"validation\"][\"input_ids\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b42986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 894 μs, sys: 65 μs, total: 959 μs\n",
      "Wall time: 760 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset[\"train\"][0][\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7c36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# dataset[\"train\"][\"input_ids\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72909609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_token_lists(stories, max_length=513):\n",
    "    \"\"\"\n",
    "    Packs token lists into batches without exceeding max_length.\n",
    "    \n",
    "    Args:\n",
    "        token_lists: List of lists of token IDs\n",
    "        max_length: Maximum allowed length for each batch (default: 513)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with packed inputs no longer than max_length (not padded)\n",
    "    \"\"\"\n",
    "    # Sort token lists in descending order of length to improve packing efficiency\n",
    "    stories_len_sorted = sorted(stories[\"input_ids\"], key=len, reverse=True)\n",
    "    \n",
    "    inputs = []\n",
    "    \n",
    "    for story in stories_len_sorted:\n",
    "        placed = False\n",
    "        story_length = len(story)\n",
    "\n",
    "        if story_length >= max_length:\n",
    "            # truncate the token list if it exceeds max_length\n",
    "            story = story[:max_length]\n",
    "            inputs.append(story)\n",
    "            placed = True\n",
    "            continue\n",
    "        \n",
    "        # Try to find an existing input that can accommodate this token list\n",
    "        for input in inputs:\n",
    "            input_length = len(input)\n",
    "            if input_length + story_length <= max_length:\n",
    "                input.extend(story)\n",
    "                placed = True\n",
    "                break\n",
    "                \n",
    "        # If no existing batch can accommodate, create a new batch\n",
    "        if not placed:\n",
    "            inputs.append(story)\n",
    "\n",
    "    return {\n",
    "        \"packed_inputs\": inputs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d181e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=23): 100%|██████████| 2119719/2119719 [00:10<00:00, 199224.90 examples/s]\n",
      "Map (num_proc=23): 100%|██████████| 21990/21990 [00:00<00:00, 96749.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "  pack_token_lists,\n",
    "  batched=True,\n",
    "  remove_columns=[\"input_ids\"],\n",
    "  num_proc=23,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5c665bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad inputs to max length\n",
    "def pad_sequences(examples, max_length=513, padding_value=endoftext_token[0]):\n",
    "    \"\"\"\n",
    "    Pads sequences to a fixed length.\n",
    "    \n",
    "    Args:\n",
    "        examples: Dictionary containing packed inputs\n",
    "        max_length: Desired length for padding (default: 513)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with padded sequences\n",
    "    \"\"\"\n",
    "    # Pad each sequence to the specified max_length\n",
    "    padded_inputs = [\n",
    "        sequence + [padding_value] * (max_length - len(sequence)) if len(sequence) < max_length else sequence[:max_length]\n",
    "        for sequence in examples[\"packed_inputs\"]\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": padded_inputs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3980b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=23): 100%|██████████| 942538/942538 [00:09<00:00, 99052.37 examples/s] \n",
      "Map (num_proc=23): 100%|██████████| 9489/9489 [00:00<00:00, 41550.83 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "  pad_sequences,\n",
    "  batched=True,\n",
    "  remove_columns=[\"packed_inputs\"],\n",
    "  num_proc=23,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e412ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fbf8acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 942538\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 9489\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a4c2ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create square attention mask for sequence packed inputs\n",
    "def create_attention_mask(example, padding_value=endoftext_token[0]):\n",
    "    \"\"\"\n",
    "    Creates an attention mask for packed inputs.\n",
    "    \n",
    "    Args:\n",
    "        example: padded input example\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with attention masks\n",
    "    \"\"\"\n",
    "\n",
    "    # get indexes of padding tokens\n",
    "    input_ids = np.array(example[\"input_ids\"])\n",
    "    padding_indexes = np.where(input_ids == endoftext_token[0])[0]\n",
    "\n",
    "    # Create a square attention mask\n",
    "    # the attention mask should be 0 if there is a padding token between i and j and 1 otherwise\n",
    "    attention_mask = np.ones((len(input_ids), len(input_ids)), dtype=np.bool)\n",
    "    for padding_index in padding_indexes:\n",
    "        # each story delineated by a padding token\n",
    "        # set attention to 0 for all tokens outside of the story\n",
    "        attention_mask[:padding_index+1, padding_index+1:] = 0\n",
    "        attention_mask[padding_index+1:, :padding_index+1] = 0\n",
    "    \n",
    "    return {\n",
    "        \"packed_inputs\": example[\"input_ids\"],\n",
    "        \"attention_mask\": attention_mask,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41d281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=23): 100%|██████████| 942538/942538 [00:55<00:00, 17087.73 examples/s]\n",
      "Map (num_proc=23): 100%|██████████| 9489/9489 [00:02<00:00, 4440.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    create_attention_mask,\n",
    "    batched=False,\n",
    "    remove_columns=[\"input_ids\"],\n",
    "    num_proc=23,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0eccbc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (74/74 shards): 100%|██████████| 942538/942538 [00:57<00:00, 16255.35 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 9489/9489 [00:00<00:00, 22509.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk(\"packed_dataset_with_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "120e2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage:\n",
    "\n",
    "from datasets import load_from_disk\n",
    "packed_dataset = load_from_disk(\"packed_dataset_with_mask\")\n",
    "packed_dataset.set_format('torch')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# Create DataLoader\n",
    "dataloader_train = DataLoader(packed_dataset[\"train\"], batch_size=16, shuffle=True)\n",
    "dataloader_valid = DataLoader(packed_dataset[\"validation\"], batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a6d7bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first batch\n",
    "for input in dataloader_train:\n",
    "    first_batch = input\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7d018431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'packed_inputs': tensor([[  337,   228,   426,  ..., 30000, 30000, 30000],\n",
       "         [  694,   228,   337,  ..., 30000, 30000, 30000],\n",
       "         [  374,   379,    68,  ...,   250,    18, 30000],\n",
       "         ...,\n",
       "         [ 7610,   238,   523,  ..., 30000, 30000, 30000],\n",
       "         [  374,   379,    68,  ..., 30000, 30000, 30000],\n",
       "         [  324,   228,   442,  ...,   339,     5, 30000]]),\n",
       " 'attention_mask': tensor([[[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ...,  True, False, False],\n",
       "          [False, False, False,  ..., False,  True, False],\n",
       "          [False, False, False,  ..., False, False,  True]],\n",
       " \n",
       "         [[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ...,  True, False, False],\n",
       "          [False, False, False,  ..., False,  True, False],\n",
       "          [False, False, False,  ..., False, False,  True]],\n",
       " \n",
       "         [[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ...,  True,  True,  True]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ...,  True, False, False],\n",
       "          [False, False, False,  ..., False,  True, False],\n",
       "          [False, False, False,  ..., False, False,  True]],\n",
       " \n",
       "         [[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ...,  True, False, False],\n",
       "          [False, False, False,  ..., False,  True, False],\n",
       "          [False, False, False,  ..., False, False,  True]],\n",
       " \n",
       "         [[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ...,  True,  True,  True]]])}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab69043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
